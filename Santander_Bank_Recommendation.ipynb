{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Column Name\t  Description\n",
    "fecha_dato\t          The table is partitioned for this column\n",
    "ncodpers\t          Customer code\n",
    "ind_empleado\t      Employee index: \n",
    "                        A active, \n",
    "                        B ex employed, \n",
    "                        F filial, \n",
    "                        N not employee, \n",
    "                        P passive\n",
    "pais_residencia\t      Customer's Country residence\n",
    "sexo\t              Customer's sex\n",
    "age\t                  Age\n",
    "fecha_alta\t          The date in which the customer became as the first holder of a contract in the bank\n",
    "ind_nuevo\t          New customer Index. 1 if the customer registered in the last 6 months.\n",
    "antiguedad\t          Customer seniority (in months)\n",
    "indrel\t              1 (First/Primary), \n",
    "                      99 (Primary customer during the month but not at the end of the month)\n",
    "ult_fec_cli_1t\t      Last date as primary customer (if he isn't at the end of the month)\n",
    "indrel_1mes\t          Customer type at the beginning of the month ,\n",
    "                        1 (First/Primary customer), \n",
    "                        2 (co-owner ),\n",
    "                        P (Potential),\n",
    "                        3 (former primary), \n",
    "                        4(former co-owner)\n",
    "tiprel_1mes\t          Customer relation type at the beginning of the month, \n",
    "                        A (active), \n",
    "                        I (inactive), \n",
    "                        P (former customer),\n",
    "                        R (Potential)\n",
    "indresi\t              Residence index \n",
    "                        (S (Yes) or N (No) if the residence country is the same than the bank country)\n",
    "indext\t              Foreigner index \n",
    "                        (S (Yes) or N (No) if the customer's birth country is different than the bank country)\n",
    "conyuemp\t          Spouse index. \n",
    "                        1 if the customer is spouse of an employee\n",
    "canal_entrada\t      channel used by the customer to join\n",
    "indfall\t              Deceased index. N/S\n",
    "tipodom\t              Addres type. 1, primary address\n",
    "cod_prov\t          Province code (customer's address)\n",
    "nomprov\t              Province name\n",
    "ind_actividad_cliente\tActivity index \n",
    "                        (1, active customer; \n",
    "                        0, inactive customer)\n",
    "renta\t              Gross income of the household\n",
    "segmento\t          segmentation: \n",
    "                        01 - VIP, \n",
    "                        02 - Individuals \n",
    "                        03 - college graduated\n",
    "ind_ahor_fin_ult1\t  Saving Account\n",
    "ind_aval_fin_ult1\t  Guarantees\n",
    "ind_cco_fin_ult1\t  Current Accounts\n",
    "ind_cder_fin_ult1\t  Derivada Account\n",
    "ind_cno_fin_ult1\t  Payroll Account\n",
    "ind_ctju_fin_ult1\t  Junior Account\n",
    "ind_ctma_fin_ult1\t  Más particular Account\n",
    "ind_ctop_fin_ult1\t  particular Account\n",
    "ind_ctpp_fin_ult1\t  particular Plus Account\n",
    "ind_deco_fin_ult1\t  Short-term deposits\n",
    "ind_deme_fin_ult1\t  Medium-term deposits\n",
    "ind_dela_fin_ult1\t  Long-term deposits\n",
    "ind_ecue_fin_ult1\t  e-account\n",
    "ind_fond_fin_ult1\t  Funds\n",
    "ind_hip_fin_ult1\t  Mortgage\n",
    "ind_plan_fin_ult1\t  Pensions\n",
    "ind_pres_fin_ult1\t  Loans\n",
    "ind_reca_fin_ult1\t  Taxes\n",
    "ind_tjcr_fin_ult1\t  Credit Card\n",
    "ind_valo_fin_ult1\t  Securities\n",
    "ind_viv_fin_ult1\t  Home Account\n",
    "ind_nomina_ult1\t      Payroll\n",
    "ind_nom_pens_ult1\t  Pensions\n",
    "ind_recibo_ult1\t      Direct Debit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import random\n",
    "from operator import sub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'ind_empleado'  : {-99:0, 'N':1, 'B':2, 'F':3, 'A':4, 'S':5},\n",
    "'sexo'          : {'V':0, 'H':1, -99:2},\n",
    "'ind_nuevo'     : {'0':0, '1':1, -99:1},\n",
    "'indrel'        : {'1':0, '99':1, -99:1},\n",
    "'indrel_1mes'   : {-99:0, '1.0':1, '1':1, '2.0':2, '2':2, '3.0':3, '3':3, '4.0':4, '4':4, 'P':5},\n",
    "'tiprel_1mes'   : {-99:0, 'I':1, 'A':2, 'P':3, 'R':4, 'N':5},\n",
    "'indresi'       : {-99:0, 'S':1, 'N':2},\n",
    "'indext'        : {-99:0, 'S':1, 'N':2},\n",
    "#'conyuemp'      : {-99:0, 'S':1, 'N':2},\n",
    "'indfall'       : {-99:0, 'S':1, 'N':2},\n",
    "#'tipodom'       : {-99:0, '1':1},\n",
    "'ind_actividad_cliente' : {'0':0, '1':1, -99:2},\n",
    "'segmento'      : {'02 - PARTICULARES':0, '03 - UNIVERSITARIO':1, '01 - TOP':2, -99:3},\n",
    "'pais_residencia' : {'LV': 102, 'BE': 12, 'BG': 50, 'BA': 61, 'BM': 117, 'BO': 62, 'JP': 82, 'JM': 116, 'BR': 17, 'BY': 64, 'BZ': 113, 'RU': 43, 'RS': 89, 'RO': 41, 'GW': 99, 'GT': 44, 'GR': 39, 'GQ': 73, 'GE': 78, 'GB': 9, 'GA': 45, 'GN': 98, 'GM': 110, 'GI': 96, 'GH': 88, 'OM': 100, 'HR': 67, 'HU': 106, 'HK': 34, 'HN': 22, 'AD': 35, 'PR': 40, 'PT': 26, 'PY': 51, 'PA': 60, 'PE': 20, 'PK': 84, 'PH': 91, 'PL': 30, 'EE': 52, 'EG': 74, 'ZA': 75, 'EC': 19, 'AL': 25, 'VN': 90, 'ET': 54, 'ZW': 114, 'ES': 0, 'MD': 68, 'UY': 77, 'MM': 94, 'ML': 104, 'US': 15, 'MT': 118, 'MR': 48, 'UA': 49, 'MX': 16, 'IL': 42, 'FR': 8, 'MA': 38, 'FI': 23, 'NI': 33, 'NL': 7, 'NO': 46, 'NG': 83, 'NZ': 93, 'CI': 57, 'CH': 3, 'CO': 21, 'CN': 28, 'CM': 55, 'CL': 4, 'CA': 2, 'CG': 101, 'CF': 109, 'CD': 112, 'CZ': 36, 'CR': 32, 'CU': 72, 'KE': 65, 'KH': 95, 'SV': 53, 'SK': 69, 'KR': 87, 'KW': 92, 'SN': 47, 'SL': 97, 'KZ': 111, 'SA': 56, 'SG': 66, 'SE': 24, 'DO': 11, 'DJ': 115, 'DK': 76, 'DE': 10, 'DZ': 80, 'MK': 105, -99: 1, 'LB': 81, 'TW': 29, 'TR': 70, 'TN': 85, 'LT': 103, 'LU': 59, 'TH': 79, 'TG': 86, 'LY': 108, 'AE': 37, 'VE': 14, 'IS': 107, 'IT': 18, 'AO': 71, 'AR': 13, 'AU': 63, 'AT': 6, 'IN': 31, 'IE': 5, 'QA': 58, 'MZ': 27},\n",
    "'canal_entrada' : {'013': 49, 'KHP': 160, 'KHQ': 157, 'KHR': 161, 'KHS': 162, 'KHK': 10, 'KHL': 0, 'KHM': 12, 'KHN': 21, 'KHO': 13, 'KHA': 22, 'KHC': 9, 'KHD': 2, 'KHE': 1, 'KHF': 19, '025': 159, 'KAC': 57, 'KAB': 28, 'KAA': 39, 'KAG': 26, 'KAF': 23, 'KAE': 30, 'KAD': 16, 'KAK': 51, 'KAJ': 41, 'KAI': 35, 'KAH': 31, 'KAO': 94, 'KAN': 110, 'KAM': 107, 'KAL': 74, 'KAS': 70, 'KAR': 32, 'KAQ': 37, 'KAP': 46, 'KAW': 76, 'KAV': 139, 'KAU': 142, 'KAT': 5, 'KAZ': 7, 'KAY': 54, 'KBJ': 133, 'KBH': 90, 'KBN': 122, 'KBO': 64, 'KBL': 88, 'KBM': 135, 'KBB': 131, 'KBF': 102, 'KBG': 17, 'KBD': 109, 'KBE': 119, 'KBZ': 67, 'KBX': 116, 'KBY': 111, 'KBR': 101, 'KBS': 118, 'KBP': 121, 'KBQ': 62, 'KBV': 100, 'KBW': 114, 'KBU': 55, 'KCE': 86, 'KCD': 85, 'KCG': 59, 'KCF': 105, 'KCA': 73, 'KCC': 29, 'KCB': 78, 'KCM': 82, 'KCL': 53, 'KCO': 104, 'KCN': 81, 'KCI': 65, 'KCH': 84, 'KCK': 52, 'KCJ': 156, 'KCU': 115, 'KCT': 112, 'KCV': 106, 'KCQ': 154, 'KCP': 129, 'KCS': 77, 'KCR': 153, 'KCX': 120, 'RED': 8, 'KDL': 158, 'KDM': 130, 'KDN': 151, 'KDO': 60, 'KDH': 14, 'KDI': 150, 'KDD': 113, 'KDE': 47, 'KDF': 127, 'KDG': 126, 'KDA': 63, 'KDB': 117, 'KDC': 75, 'KDX': 69, 'KDY': 61, 'KDZ': 99, 'KDT': 58, 'KDU': 79, 'KDV': 91, 'KDW': 132, 'KDP': 103, 'KDQ': 80, 'KDR': 56, 'KDS': 124, 'K00': 50, 'KEO': 96, 'KEN': 137, 'KEM': 155, 'KEL': 125, 'KEK': 145, 'KEJ': 95, 'KEI': 97, 'KEH': 15, 'KEG': 136, 'KEF': 128, 'KEE': 152, 'KED': 143, 'KEC': 66, 'KEB': 123, 'KEA': 89, 'KEZ': 108, 'KEY': 93, 'KEW': 98, 'KEV': 87, 'KEU': 72, 'KES': 68, 'KEQ': 138, -99: 6, 'KFV': 48, 'KFT': 92, 'KFU': 36, 'KFR': 144, 'KFS': 38, 'KFP': 40, 'KFF': 45, 'KFG': 27, 'KFD': 25, 'KFE': 148, 'KFB': 146, 'KFC': 4, 'KFA': 3, 'KFN': 42, 'KFL': 34, 'KFM': 141, 'KFJ': 33, 'KFK': 20, 'KFH': 140, 'KFI': 134, '007': 71, '004': 83, 'KGU': 149, 'KGW': 147, 'KGV': 43, 'KGY': 44, 'KGX': 24, 'KGC': 18, 'KGN': 11}\n",
    "}\n",
    "cat_cols = list(mapping_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This is a list of target columns (22 out of 24, as 2 products are not used at all in Jun 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "target_cols = target_cols[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is to fetch a single row from the dataset and return target columns in a list\n",
    "def getTarget(row):\n",
    "    tlist = []\n",
    "    for col in target_cols:\n",
    "        if row[col].strip() in ['', 'NA']:\n",
    "            target = 0\n",
    "        else:\n",
    "            target = int(float(row[col]))\n",
    "        tlist.append(target)\n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function encodes the values from the mapping dictionary created above\n",
    "def getIndex(row, col):\n",
    "    val = row[col].strip()\n",
    "    if val not in ['','NA']:\n",
    "        ind = mapping_dict[col][val]\n",
    "    else:\n",
    "        ind = mapping_dict[col][-99]\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have age distribution from 0 to 164 in the data. Considering humans do live upto 100 years, I am impute \n",
    "#missing value to be the mean age(40) and standarize the age variable\n",
    "\n",
    "def getAge(row):\n",
    "    mean_age = 40.\n",
    "    min_age = 0.\n",
    "    max_age = 100.\n",
    "    range_age = max_age - min_age\n",
    "    age = row['age'].strip()\n",
    "    if age == 'NA' or age == '':\n",
    "        age = mean_age\n",
    "    else:\n",
    "        age = float(age)\n",
    "        if age < min_age:\n",
    "            age = min_age\n",
    "        elif age > max_age:\n",
    "            age = max_age\n",
    "    return round( (age - min_age) / range_age, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a variable called CustomerSeniority which has values ranging from 0 to 256. This function imputes missing values\n",
    "#to be 0 and then standardize the variable\n",
    "\n",
    "def getCustSeniority(row):\n",
    "    min_value = 0.\n",
    "    max_value = 256.\n",
    "    range_value = max_value - min_value\n",
    "    missing_value = 0.\n",
    "    cust_seniority = row['antiguedad'].strip()\n",
    "    if cust_seniority == 'NA' or cust_seniority == '':\n",
    "        cust_seniority = missing_value\n",
    "    else:\n",
    "        cust_seniority = float(cust_seniority)\n",
    "        if cust_seniority < min_value:\n",
    "            cust_seniority = min_value\n",
    "        elif cust_seniority > max_value:\n",
    "            cust_seniority = max_value\n",
    "    return round((cust_seniority-min_value) / range_value, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have tried various methods for imputing the houshold income, and this method gave me better results\n",
    "# This function takes the median household income based on city and imputes missing household income as median \n",
    "# household income of all data and then standardise the household income\n",
    "\n",
    "def getRent(row):\n",
    "    min_value = 0.\n",
    "    max_value = 1354778.\n",
    "    range_value = max_value - min_value\n",
    "    renta_dict = {'ALAVA': 96967,\n",
    " 'ALBACETE': 78657,\n",
    " 'ALICANTE': 67526,\n",
    " 'ALMERIA': 73390,\n",
    " 'ASTURIAS': 87199,\n",
    " 'AVILA': 68561,\n",
    " 'BADAJOZ': 62330,\n",
    " 'BALEARS, ILLES': 123573,\n",
    " 'BARCELONA': 131214,\n",
    " 'BIZKAIA': 99978,\n",
    " 'BURGOS': 89385,\n",
    " 'CACERES': 67799,\n",
    " 'CADIZ': 79016,\n",
    " 'CANTABRIA': 95517,\n",
    " 'CASTELLON': 66630,\n",
    " 'CEUTA': 128699,\n",
    " 'CIUDAD REAL': 62193,\n",
    " 'CORDOBA': 69106,\n",
    " #'CORUÑA, A': 97689,\n",
    "'CORUÃ‘A, A':97689,\n",
    " 'CUENCA': 67201,\n",
    " 'GIPUZKOA': 80599,\n",
    " 'GIRONA': 108963,\n",
    " 'GRANADA': 82447,\n",
    " 'GUADALAJARA': 92724,\n",
    " 'HUELVA': 68994,\n",
    " 'HUESCA': 73467,\n",
    " 'JAEN': 67886,\n",
    " 'LEON': 80901,\n",
    " 'LERIDA': 64818,\n",
    " 'LUGO': 64390,\n",
    " 'MADRID': 139070,\n",
    " 'MALAGA': 95102,\n",
    " 'MELILLA': 117408,\n",
    " 'MURCIA': 67813,\n",
    " 'NAVARRA': 86649,\n",
    " 'OURENSE': 79069,\n",
    " 'PALENCIA': 86593,\n",
    " 'PALMAS, LAS': 80948,\n",
    " 'PONTEVEDRA': 97829,\n",
    " 'RIOJA, LA': 89936,\n",
    " 'SALAMANCA': 89831,\n",
    " 'SANTA CRUZ DE TENERIFE': 82729,\n",
    " 'SEGOVIA': 89311,\n",
    " 'SEVILLA': 92710,\n",
    " 'SORIA': 78810,\n",
    " 'TARRAGONA': 88283,\n",
    " 'TERUEL': 76467,\n",
    " 'TOLEDO': 68867,\n",
    " 'UNKNOWN':101850,\n",
    " 'VALENCIA': 72988,\n",
    " 'VALLADOLID': 92880,\n",
    " 'ZAMORA': 74692,\n",
    " 'ZARAGOZA': 99950}\n",
    "\n",
    "    #missing_value = 101850.\n",
    "    rent = row['renta'].strip()\n",
    "    if rent == 'NA' or rent == '':\n",
    "        if row['nomprov'] == 'NA' or row['nomprov'] == '':\n",
    "            rent = float(renta_dict['UNKNOWN'])\n",
    "        else:\n",
    "            rent = float(renta_dict[row['nomprov']])\n",
    "    else:\n",
    "        rent = float(rent)\n",
    "        if rent < min_value:\n",
    "            rent = min_value\n",
    "        elif rent > max_value:\n",
    "            rent = max_value\n",
    "\n",
    "    return round((rent-min_value) / range_value, 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Married flag - Based on department of Staistics spanish report, I tried creating married flag. But that method \n",
    "# did not work very well. So calculated married flag based on general knowledge. \n",
    "# This is not very predictive though.\n",
    "\n",
    "def getMarriageIndex(row, age, sex, income):    \n",
    "    if age <= 25:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is a high difference in number of customer joining by month, I decided to calculate the month. \n",
    "# This function returns the joining month.\n",
    "\n",
    "def getjoinMonth(row):\n",
    "    if row['fecha_alta'].strip() == 'NA' or row['fecha_alta'].strip() == '':\n",
    "        return int(random.choice([1,2,3,4,5,6,7,8,9,10,11,12]))\n",
    "    else:\n",
    "        return int(row['fecha_alta'].split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a very important function which does a lot of things:\n",
    "# I have used train data to be Jun 2015 and test data to be Jun 2016. This is because there is severe change in number\n",
    "# of products being bought per month. \n",
    "# 1. It calculates the new products bought for 2015(train data)\n",
    "# 2. It calculates the lags for each product for train and test data.\n",
    "# 3. Applied all the transformations mentioned above in all functions \n",
    "# 4. Create a final dataset which is passed on to XGB for predictions\n",
    "\n",
    "def processData(in_file_name, cust_dict, lag_cust_dict,lag_cust_dict1,lag_cust_dict2,lag_cust_dict3,lag_cust_dict4):\n",
    "    x_vars_list = []\n",
    "    y_vars_list = []\n",
    "    \n",
    "    for row in csv.DictReader(in_file_name):\n",
    "        #Use only 6 months\n",
    "        if row['fecha_dato'] not in ['2015-01-28','2015-02-28','2015-03-28','2015-04-28', '2015-05-28', '2015-06-28', '2016-01-28','2016-02-28','2016-03-28','2016-04-28', '2016-05-28', '2016-06-28']:\n",
    "            continue\n",
    "\n",
    "        cust_id = int(row['ncodpers'])\n",
    "        #print(row['fecha_dato'])\n",
    "        if (row['fecha_dato'] in ['2015-01-28', '2016-01-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag_cust_dict4[cust_id] =  target_list[:]\n",
    "            continue\n",
    "            \n",
    "        if (row['fecha_dato'] in ['2015-02-28', '2016-02-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag_cust_dict3[cust_id] =  target_list[:]\n",
    "            continue\n",
    "            \n",
    "        if (row['fecha_dato'] in ['2015-03-28', '2016-03-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag_cust_dict2[cust_id] =  target_list[:]\n",
    "            continue\n",
    "            \n",
    "        if (row['fecha_dato'] in ['2015-04-28', '2016-04-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag_cust_dict1[cust_id] =  target_list[:]\n",
    "            continue\n",
    "        \n",
    "        if (row['fecha_dato'] in ['2015-05-28', '2016-05-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "        \n",
    "        x_vars = []\n",
    "        for col in cat_cols:\n",
    "            x_vars.append( getIndex(row, col) )\n",
    "        sex = getIndex(row, 'sexo')\n",
    "        age = getAge(row)\n",
    "        x_vars.append(age)\n",
    "        #x_vars.append( getMonth(row))\n",
    "        x_vars.append( getjoinMonth(row))\n",
    "        x_vars.append(getCustSeniority(row))\n",
    "        income = getRent(row)\n",
    "        x_vars.append(income)\n",
    "        x_vars.append(getMarriageIndex(row, age, sex, income) )\n",
    "        if row['fecha_dato'] == '2016-06-28':\n",
    "            prev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "            lag_target_list = lag_cust_dict.get(cust_id, [0]*22)\n",
    "            lag_target_list1 = lag_cust_dict1.get(cust_id, [0]*22)\n",
    "            lag_target_list2 = lag_cust_dict2.get(cust_id, [0]*22)\n",
    "            lag_target_list3 = lag_cust_dict3.get(cust_id, [0]*22)\n",
    "            lag_target_list4 = lag_cust_dict4.get(cust_id, [0]*22)\n",
    "            x_vars_list.append(x_vars + prev_target_list + lag_target_list+lag_target_list1+lag_target_list2+lag_target_list3+lag_target_list4)\n",
    "        elif row['fecha_dato'] == '2015-06-28':\n",
    "            prev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "            lag_target_list = lag_cust_dict.get(cust_id, [0]*22)\n",
    "            lag_target_list1 = lag_cust_dict1.get(cust_id, [0]*22)\n",
    "            lag_target_list2 = lag_cust_dict2.get(cust_id, [0]*22)\n",
    "            lag_target_list3 = lag_cust_dict3.get(cust_id, [0]*22)\n",
    "            lag_target_list4 = lag_cust_dict4.get(cust_id, [0]*22)\n",
    "            target_list = getTarget(row)\n",
    "            new_products = [max(x1 - x2,0) for (x1, x2) in zip(target_list, prev_target_list)]\n",
    "            if sum(new_products) > 0:\n",
    "                for ind, prod in enumerate(new_products):\n",
    "                    if prod>0:\n",
    "                        assert len(prev_target_list) == 22\n",
    "                        x_vars_list.append(x_vars+prev_target_list+lag_target_list+lag_target_list1+lag_target_list2+lag_target_list3+lag_target_list4)\n",
    "                        y_vars_list.append(ind)        \n",
    "        \n",
    "    return x_vars_list, y_vars_list, cust_dict, lag_cust_dict, lag_cust_dict1, lag_cust_dict2,lag_cust_dict3,lag_cust_dict4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, seed_val=25):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.08\n",
    "    param['max_depth'] = 7\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 22\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.9\n",
    "    param['colsample_bytree'] = 0.9\n",
    "    param['seed'] = seed_val\n",
    "    param['gamma'] = 0.15 \n",
    "    param['reg-alpha']=0.075\n",
    "    num_rounds = 100\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\t\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file processing <_io.TextIOWrapper name='C:\\\\Users\\\\Anshul.Dhingra\\\\Desktop\\\\Bank_Recommendation\\\\train_ver2.csv' mode='r' encoding='cp1252'>\n",
      "Finished file processing\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "(45679, 150) (45679,)\n",
      "0:16:47.757101\n",
      "(929615, 150)\n",
      "0:18:54.230725\n"
     ]
    }
   ],
   "source": [
    "import datetime,csv\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = datetime.datetime.now()\n",
    "    data_path = \"C:\\\\Users\\\\Anshul.Dhingra\\\\Desktop\\\\Bank_Recommendation\\\\\"\n",
    "    train_file =  open(data_path + \"train_ver2.csv\")\n",
    "    print('Starting file processing', train_file)\n",
    "    #x_vars_list, y_vars_list, cust_dict = processData(train_file, {})\n",
    "    x_vars_list, y_vars_list, cust_dict, lag_cust_dict,lag_cust_dict1,lag_cust_dict2,lag_cust_dict3,lag_cust_dict4 = processData(train_file, {}, {},{},{},{},{})\n",
    "    print('Finished file processing')\n",
    "    train_X = np.array(x_vars_list)\n",
    "    train_y = np.array(y_vars_list)\n",
    "    print(np.unique(train_y))\n",
    "    del x_vars_list, y_vars_list\n",
    "    train_file.close()\n",
    "    print(train_X.shape, train_y.shape)\n",
    "    print(datetime.datetime.now()-start_time)\n",
    "    test_file = open(data_path + \"test_ver2.csv\")\n",
    "    x_vars_list, y_vars_list, cust_dict, lag_cust_dict,lag_cust_dict1,lag_cust_dict2,lag_cust_dict3,lag_cust_dict4 = processData(test_file, cust_dict, lag_cust_dict,lag_cust_dict1,lag_cust_dict2,lag_cust_dict3,lag_cust_dict4)\n",
    "    test_X = np.array(x_vars_list)\n",
    "    del x_vars_list\n",
    "    test_file.close()\n",
    "    print(test_X.shape)\n",
    "    print(datetime.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model\n",
      "Training model completed\n",
      "{'gamma': 0.8}\n",
      "0.35753519267528866\n",
      "gamma: 0.8\n",
      "[21 21 21 ... 21 21  0]\n",
      "0:04:44.930201\n"
     ]
    }
   ],
   "source": [
    "# Parameter tunning in Xtreme gradient Boosting\n",
    "\n",
    "import sys\n",
    "import math\n",
    " \n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "#sys.path.append('xgboost/wrapper/')\n",
    "import xgboost as xgb\n",
    " \n",
    "class XGBoostClassifier():\n",
    "    def __init__(self, num_boost_round=10, **params):\n",
    "        self.clf = None\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.params = params\n",
    "        self.params.update({'objective': 'multi:softprob'})\n",
    " \n",
    "    def fit(self, X, y, num_boost_round=None):\n",
    "        num_boost_round = num_boost_round or self.num_boost_round\n",
    "        self.label2num = dict((label, i) for i, label in enumerate(sorted(set(y))))\n",
    "        dtrain = xgb.DMatrix(X, label=[self.label2num[label] for label in y])\n",
    "        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    " \n",
    "    def predict(self, X):\n",
    "        num2label = dict((i, label)for label, i in self.label2num.items())\n",
    "        Y = self.predict_proba(X)\n",
    "        y = np.argmax(Y, axis=1)\n",
    "        return np.array([num2label[i] for i in y])\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self.clf.predict(dtest)\n",
    " \n",
    "    def score(self, X, y):\n",
    "        Y = self.predict_proba(X)\n",
    "        return 1 / logloss(y, Y)\n",
    " \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "def logloss(y_true, Y_pred):\n",
    "    label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))\n",
    "    return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf for y, label in zip(Y_pred, y_true)) / len(Y_pred)\n",
    "\n",
    "\n",
    "def main():\n",
    "    clf = XGBoostClassifier(\n",
    "        eval_metric = 'logloss',\n",
    "        num_class = 22,\n",
    "        nthread = 4,\n",
    "        eta = 0.07,\n",
    "        num_boost_round = 10,\n",
    "        max_depth = 9,\n",
    "        min_child_weight = 1,\n",
    "        subsample = 0.85,\n",
    "        colsample_bytree = 0.8,\n",
    "        silent = 1,\n",
    "        reg_alpha=0.07,\n",
    "        gamma = 0.9\n",
    "        )\n",
    "    parameters = {\n",
    "        'gamma':[0.6, 0.7,0.8,0.9,1]\n",
    "        #'num_boost_round': [50, 100, 150],\n",
    "        #'eta': [0.06,0.065,0.07],\n",
    "        #'reg_alpha':[0.067,0.07, 0.072,0.075]\n",
    "        #'max_depth': [7,8,9],\n",
    "        #'min_child_weight':[1,2,3]\n",
    "        #'subsample': [0.9, 0.8, 0.85, 0.95],\n",
    "        #'colsample_bytree': [0.8,0.85, 0.9, 0.95],\n",
    "    }\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs=1, cv=2)\n",
    "    print(\"Fitting the model\")\n",
    "    clf.fit(train_X,train_y)\n",
    "    print(\"Training model completed\")\n",
    "    #best_parameters, score, _ = max(clf.best_score_, key=lambda x: x[1])\n",
    "    best_parameters = clf.best_params_\n",
    "    score = clf.best_score_\n",
    "    print(best_parameters)\n",
    "    print(score)\n",
    "    \n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "                \n",
    "    print(clf.predict(test_X))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time=datetime.datetime.now()\n",
    "    main()\n",
    "    print(datetime.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Sample output of hyper-parameter tunning\n",
    "#trained all parameters individually and used the optimum hyper-parameters in the model for prediction\n",
    "\n",
    "Parameter tunning - Gamma\n",
    "Fitting the model\n",
    "Training model completed\n",
    "0.354282803146\n",
    "gamma: 0.8\n",
    "[21 21 21 ..., 21 21  0]\n",
    "0:00:44.938134\n",
    "-------------------------------\n",
    "Parameter tunning - Learning Rate(eta)\n",
    "Fitting the model\n",
    "Training model completed\n",
    "0.355558615187\n",
    "eta: 0.08\n",
    "[21 21 21 ..., 21 21  0]\n",
    "0:00:41.614512\n",
    "-------------------------------\n",
    "Parameter tunning - reg-alpha\n",
    "Fitting the model\n",
    "Training model completed\n",
    "0.355552410171\n",
    "reg_alpha: 0.065\n",
    "[21 21 21 ..., 21 21  0]\n",
    "0:00:38.515044\n",
    "-------------------------------\n",
    "Parameter tunning - reg-alpha\n",
    "Fitting the model\n",
    "Training model completed\n",
    "0.355571445945\n",
    "reg_alpha: 0.075\n",
    "[21 21 21 ..., 21 21  0]\n",
    "0:00:47.893021\n",
    "-------------------------------\n",
    "Parameter tunning - max-depth, min_child_weight\n",
    "Training model completed\n",
    "0.355973424711\n",
    "max_depth: 9\n",
    "min_child_weight: 3\n",
    "[21 21 21 ..., 21 21  0]\n",
    "0:01:38.625856\n",
    "-------------------------------\n",
    "Parameter tunning - subsample, colsample_bytree\n",
    "Fitting the model\n",
    "Training model completed\n",
    "0.356127246451\n",
    "colsample_bytree: 0.9\n",
    "subsample: 0.9\n",
    "[21 21 21 ..., 21 21  0]\n",
    "0:07:25.183973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model..\n",
      "Predicting..\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model..\")\n",
    "model = runXGB(train_X, train_y, seed_val=0)\n",
    "print(\"Predicting..\")\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "preds = model.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the top products..\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting the top products..\")\n",
    "test_id = np.array(pd.read_csv(data_path + \"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "new_products = []\n",
    "for i, idx in enumerate(test_id):\n",
    "    new_products.append([max(x1 - x2,0) for (x1, x2) in zip(preds[i,:], cust_dict[idx])])\n",
    "target_cols = np.array(target_cols)\n",
    "preds = np.argsort(np.array(new_products), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0, 16,  6, ...,  9, 15, 21],\n",
       "        [ 0, 18, 12, ..., 19, 15, 21],\n",
       "        [ 0, 18,  3, ..., 19, 20, 21],\n",
       "        ...,\n",
       "        [ 0,  5, 18, ...,  9, 16, 21],\n",
       "        [ 0, 18, 12, ..., 20, 15, 21],\n",
       "        [ 5, 18,  3, ..., 21,  8,  0]], dtype=int64), (929615, 22))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#DROP product 7,8,9,12,18 as these items have not been purchased /not popular in recent months. \n",
    "l1 = []\n",
    "for i,item in enumerate(preds):\n",
    "    l1.append(filter(lambda x: x not in (7,8,9,12,18),preds[i,:]))\n",
    "\n",
    "new_pred = np.asarray(l1)\n",
    "new_pred = np.fliplr([new_pred])[:,:7]\n",
    "final_preds = [\" \".join(list(target_cols[pred])) for pred in new_pred]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "out_df.to_csv('submission28.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anshul.Dhingra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>indext</th>\n",
       "      <th>conyuemp</th>\n",
       "      <th>canal_entrada</th>\n",
       "      <th>indfall</th>\n",
       "      <th>tipodom</th>\n",
       "      <th>cod_prov</th>\n",
       "      <th>nomprov</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>renta</th>\n",
       "      <th>segmento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>56</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1</td>\n",
       "      <td>326124.90</td>\n",
       "      <td>01 - TOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170544</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>36</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ALICANTE</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>02 - PARTICULARES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170545</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>CORUÑA, A</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170547</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>0</td>\n",
       "      <td>148402.98</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170548</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BALEARS, ILLES</td>\n",
       "      <td>0</td>\n",
       "      <td>106885.80</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  fecha_alta  \\\n",
       "0  2016-06-28     15889            F              ES    V   56  1995-01-16   \n",
       "1  2016-06-28   1170544            N              ES    H   36  2013-08-28   \n",
       "2  2016-06-28   1170545            N              ES    V   22  2013-08-28   \n",
       "3  2016-06-28   1170547            N              ES    H   22  2013-08-28   \n",
       "4  2016-06-28   1170548            N              ES    H   22  2013-08-28   \n",
       "\n",
       "   ind_nuevo  antiguedad  indrel         ...         indext  conyuemp  \\\n",
       "0          0         256       1         ...              N         N   \n",
       "1          0          34       1         ...              N       NaN   \n",
       "2          0          34       1         ...              N       NaN   \n",
       "3          0          34       1         ...              N       NaN   \n",
       "4          0          34       1         ...              N       NaN   \n",
       "\n",
       "  canal_entrada indfall tipodom cod_prov         nomprov  \\\n",
       "0           KAT       N       1     28.0          MADRID   \n",
       "1           KAT       N       1      3.0        ALICANTE   \n",
       "2           KHE       N       1     15.0       CORUÑA, A   \n",
       "3           KHE       N       1      8.0       BARCELONA   \n",
       "4           KHE       N       1      7.0  BALEARS, ILLES   \n",
       "\n",
       "  ind_actividad_cliente        renta            segmento  \n",
       "0                     1    326124.90            01 - TOP  \n",
       "1                     0           NA   02 - PARTICULARES  \n",
       "2                     1           NA  03 - UNIVERSITARIO  \n",
       "3                     0    148402.98  03 - UNIVERSITARIO  \n",
       "4                     0    106885.80  03 - UNIVERSITARIO  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values(by = ['ncodpers'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n",
       "       'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n",
       "       'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'cod_prov',\n",
       "       'nomprov', 'ind_actividad_cliente', 'renta', 'segmento'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test['Current_Holding'] = np.random.choice(['Savings_Account', 'Life_Insurance', 'Locker'], size=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>conyuemp</th>\n",
       "      <th>canal_entrada</th>\n",
       "      <th>indfall</th>\n",
       "      <th>tipodom</th>\n",
       "      <th>cod_prov</th>\n",
       "      <th>nomprov</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>renta</th>\n",
       "      <th>segmento</th>\n",
       "      <th>Current_Holding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>56</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1</td>\n",
       "      <td>326124.90</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>Locker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618359</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15890</td>\n",
       "      <td>A</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>63</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1</td>\n",
       "      <td>71461.20</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>Life_Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618360</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>62</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1</td>\n",
       "      <td>430477.41</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>Locker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618361</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15893</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>63</td>\n",
       "      <td>1997-10-03</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1</td>\n",
       "      <td>430477.41</td>\n",
       "      <td>02 - PARTICULARES</td>\n",
       "      <td>Life_Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618362</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15894</td>\n",
       "      <td>A</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>60</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1</td>\n",
       "      <td>281757.72</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>Savings_Account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  \\\n",
       "0       2016-06-28     15889            F              ES    V   56   \n",
       "618359  2016-06-28     15890            A              ES    V   63   \n",
       "618360  2016-06-28     15892            F              ES    H   62   \n",
       "618361  2016-06-28     15893            N              ES    V   63   \n",
       "618362  2016-06-28     15894            A              ES    V   60   \n",
       "\n",
       "        fecha_alta  ind_nuevo  antiguedad  indrel       ...        conyuemp  \\\n",
       "0       1995-01-16          0         256       1       ...               N   \n",
       "618359  1995-01-16          0         257       1       ...               N   \n",
       "618360  1995-01-16          0         257       1       ...               N   \n",
       "618361  1997-10-03          0         257       1       ...               N   \n",
       "618362  1995-01-16          0         257       1       ...               N   \n",
       "\n",
       "        canal_entrada indfall tipodom cod_prov nomprov ind_actividad_cliente  \\\n",
       "0                 KAT       N       1     28.0  MADRID                     1   \n",
       "618359            KAT       N       1     28.0  MADRID                     1   \n",
       "618360            KAT       N       1     28.0  MADRID                     1   \n",
       "618361            KAT       N       1     28.0  MADRID                     1   \n",
       "618362            KAT       N       1     28.0  MADRID                     1   \n",
       "\n",
       "              renta           segmento  Current_Holding  \n",
       "0         326124.90           01 - TOP           Locker  \n",
       "618359     71461.20           01 - TOP   Life_Insurance  \n",
       "618360    430477.41           01 - TOP           Locker  \n",
       "618361    430477.41  02 - PARTICULARES   Life_Insurance  \n",
       "618362    281757.72           01 - TOP  Savings_Account  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>added_products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15889</td>\n",
       "      <td>ind_recibo_ult1 ind_reca_fin_ult1 ind_ctop_fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15890</td>\n",
       "      <td>ind_reca_fin_ult1 ind_cco_fin_ult1 ind_dela_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15892</td>\n",
       "      <td>ind_nom_pens_ult1 ind_cno_fin_ult1 ind_nomina_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15893</td>\n",
       "      <td>ind_cco_fin_ult1 ind_tjcr_fin_ult1 ind_ctop_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15894</td>\n",
       "      <td>ind_ctop_fin_ult1 ind_cno_fin_ult1 ind_dela_fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ncodpers                                     added_products\n",
       "0     15889  ind_recibo_ult1 ind_reca_fin_ult1 ind_ctop_fin...\n",
       "1     15890  ind_reca_fin_ult1 ind_cco_fin_ult1 ind_dela_fi...\n",
       "2     15892  ind_nom_pens_ult1 ind_cno_fin_ult1 ind_nomina_...\n",
       "3     15893  ind_cco_fin_ult1 ind_tjcr_fin_ult1 ind_ctop_fi...\n",
       "4     15894  ind_ctop_fin_ult1 ind_cno_fin_ult1 ind_dela_fi..."
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.merge(test,result, on = 'ncodpers' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n",
       "       'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n",
       "       'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'cod_prov',\n",
       "       'nomprov', 'ind_actividad_cliente', 'renta', 'segmento',\n",
       "       'Current_Holding', 'added_products'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns = ['Month_status_date', 'Customer_ID', 'Employee_Index', 'Customer_country', 'Sex', 'Age', 'Join_date',\n",
    "                'New_customer', 'Relationship_Months', 'Relationship_flag','Last_date_Primary_Customer', 'Customer_type_begin_Month', 'Cust_Relation_type_begin_month',\n",
    "                'Residence_flag', 'Forigner_flag', 'Emp_spouse_flag', 'Channel_when_joined', 'Deceased_flag', \n",
    "                'Address_type', 'Customer_address', 'Address_detail', 'Activity_flag', 'Gross_household_income',\n",
    "                'Segment','Current_Holding', 'Recommended_products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('bank_recommendation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 26)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
